# Phase 7.1: Atomic File Upload - Research

**Researched:** 2026-02-07
**Domain:** Backend refactoring (NestJS + TypeORM), Frontend upload flow (React + Zustand)
**Confidence:** HIGH

## Summary

The current file upload flow requires **4+ sequential HTTP requests** per file: (1) encrypt client-side, (2) POST to `/ipfs/add` to pin, (3) POST to `/ipns/publish` to update folder metadata IPNS, (4) client-side folder state update. For multi-file uploads, IPNS is published N times (once per file via `addFileToFolder` -> `updateFolderMetadata` -> `createAndPublishIpnsRecord`), each taking ~2 seconds.

The recommended refactoring consolidates the backend portion into a single atomic endpoint that handles: pin to IPFS, record the CID for quota tracking, and attempt IPNS publish -- all in one request. On the frontend, a new `addFilesToFolder` batch function builds the complete children array and publishes IPNS exactly once after all files are uploaded.

**Primary recommendation:** Keep encryption client-side (zero-knowledge), consolidate backend to single `POST /ipfs/upload` endpoint (pin + record in DB transaction), and add `addFilesToFolder` batch function on frontend to publish IPNS once for multi-file uploads.

## Current Architecture Analysis

### Current Upload Flow (Per File)

```text
Client                                           Backend
  |                                                 |
  |-- 1. encryptFile(file, publicKey) ------------> |  (client-side, ~100ms)
  |                                                 |
  |-- 2. POST /ipfs/add (multipart: blob) -------> |  Pin to IPFS
  |<-- { cid, size } -------------------------------|  (~500ms-2s)
  |                                                 |
  |-- 3. addFileToFolder() -----------------------> |  Client builds metadata
  |   |-- updateFolderMetadata() -----------------> |
  |   |   |-- encryptFolderMetadata() ------------> |  (client-side)
  |   |   |-- POST /ipfs/add (metadata JSON) ----> |  Pin metadata (~500ms)
  |   |   |-- createAndPublishIpnsRecord() -------> |
  |   |   |   |-- createIpnsRecord() (client) ---> |  Sign locally
  |   |   |   |-- POST /ipns/publish ------------> |  Relay to delegated-ipfs.dev
  |   |   |   |<-- { success, sequenceNumber } ----|  (~1-2s)
  |                                                 |
  |-- 4. quotaStore.addUsage(size) (client) ------> |  Local state update
```

**Total per file:** 3 HTTP requests, ~3-5 seconds
**For 5 files:** 15 HTTP requests, 5 IPNS publishes, ~15-25 seconds

### Files Involved in Current Flow

| File                                                  | Role                                          | What Changes                     |
| ----------------------------------------------------- | --------------------------------------------- | -------------------------------- |
| `apps/web/src/services/upload.service.ts`             | Encrypts + uploads to IPFS                    | Add quota recording call         |
| `apps/web/src/services/folder.service.ts`             | `addFileToFolder()`, `updateFolderMetadata()` | Add batch `addFilesToFolder()`   |
| `apps/web/src/services/ipns.service.ts`               | Creates/publishes IPNS records                | No change (already used)         |
| `apps/web/src/services/file-crypto.service.ts`        | `encryptFile()`                               | No change                        |
| `apps/web/src/hooks/useFileUpload.ts`                 | Orchestrates upload                           | Wire to new batch flow           |
| `apps/web/src/hooks/useFolder.ts`                     | `addFile()` handler                           | Add `addFiles()` batch handler   |
| `apps/web/src/lib/api/ipfs.ts`                        | Axios calls to `/ipfs/add`                    | Update to use new endpoint       |
| `apps/web/src/stores/upload.store.ts`                 | Upload progress state                         | Add "registering" status         |
| `apps/web/src/components/file-browser/EmptyState.tsx` | Drop handler calls `addFile` per file in loop | Use batch addFiles               |
| `apps/web/src/components/file-browser/UploadZone.tsx` | Drop handler calls `addFile` per file in loop | Use batch addFiles               |
| `apps/api/src/ipfs/ipfs.controller.ts`                | `POST /ipfs/add` endpoint                     | Add `POST /ipfs/upload` endpoint |
| `apps/api/src/ipfs/ipfs.module.ts`                    | Wires IPFS controller + provider              | Import VaultService              |
| `apps/api/src/vault/vault.service.ts`                 | `recordPin()`, `checkQuota()`                 | No change (already has methods)  |

### Key Observations

1. **Encryption is client-side only** (zero-knowledge): The backend never sees plaintext. Encryption MUST stay on the client.

2. **IPNS signing is client-side**: The client holds Ed25519 private keys, creates IPNS records, and the backend merely relays them to delegated-ipfs.dev. IPNS publish cannot be moved to backend.

3. **Quota recording is NOT transactional**: Currently the client calls `quotaStore.addUsage()` locally but the backend's `recordPin()` in `VaultService` is never called during file upload! The `recordPin` is only used during vault initialization. This is a gap -- quota tracking relies on the `PinnedCid` table, and pins are recorded via `recordPin()`, but the current upload flow only calls `/ipfs/add` which does NOT record the pin.

4. **The real atomicity gap**: Pin to IPFS happens, but if the client crashes before registering in folder metadata, the CID is orphaned (pinned but invisible). Quota is also not tracked server-side for the pin.

5. **Per-file IPNS publish is the biggest latency issue**: For N files, N IPNS publishes happen sequentially. Each takes 1-2 seconds (delegated routing HTTP call). A batch function that publishes IPNS once would save (N-1) \* ~1.5 seconds.

## Standard Stack

### Core (Already in Project)

| Library                               | Version | Purpose                               | Status                       |
| ------------------------------------- | ------- | ------------------------------------- | ---------------------------- |
| NestJS                                | 11.1.12 | Backend framework                     | Already installed            |
| TypeORM                               | 0.3.28  | Database ORM with transaction support | Already installed            |
| Multer via `@nestjs/platform-express` | -       | File upload handling                  | Already installed            |
| `class-validator`                     | 0.14.3  | DTO validation                        | Already installed            |
| `class-transformer`                   | 0.5.1   | DTO transformation                    | Already installed            |
| axios                                 | -       | HTTP client with progress             | Already installed (frontend) |

### No New Dependencies Needed

This phase is a pure refactoring of existing code. All required libraries are already installed. No new npm packages needed.

## Architecture Patterns

### Pattern 1: Atomic Upload Endpoint (Backend)

**What:** A new `POST /ipfs/upload` endpoint that accepts multipart file + records the pin in a DB transaction.

**Why this pattern:**

- Combines pin-to-IPFS + record-in-DB into atomic operation
- Uses TypeORM transaction to ensure quota tracking is consistent
- Returns CID, size, and recorded status in single response
- IPNS publish stays on client (zero-knowledge requirement)

**Endpoint design:**

```typescript
// POST /ipfs/upload
// Content-Type: multipart/form-data
// Body: { file: Blob }
// Response: { cid: string; size: number; recorded: boolean }

@Post('upload')
@UseInterceptors(FileInterceptor('file', { limits: { fileSize: MAX_FILE_SIZE } }))
async upload(
  @Request() req: RequestWithUser,
  @UploadedFile(new ParseFilePipe({
    validators: [new MaxFileSizeValidator({ maxSize: MAX_FILE_SIZE })],
  }))
  file: Express.Multer.File,
): Promise<UploadResponseDto> {
  // 1. Check quota BEFORE pinning (fail fast)
  const hasQuota = await this.vaultService.checkQuota(req.user.id, file.size);
  if (!hasQuota) {
    throw new PayloadTooLargeException('Storage quota exceeded');
  }

  // 2. Pin to IPFS
  const { cid, size } = await this.ipfsProvider.pinFile(file.buffer);

  // 3. Record pin in DB (idempotent upsert)
  await this.vaultService.recordPin(req.user.id, cid, size);

  return { cid, size, recorded: true };
}
```

**Key design decisions:**

- Quota check happens FIRST (fail fast, no wasted IPFS pin)
- IPFS pin is NOT inside the DB transaction (external service, can't rollback)
- `recordPin` uses `orIgnore()` (idempotent -- safe to retry)
- If DB record fails after IPFS pin, the pin is orphaned but this is acceptable (fire-and-forget unpin can clean up later)

### Pattern 2: Batch Folder Update (Frontend)

**What:** New `addFilesToFolder()` function that adds multiple file entries to folder metadata and publishes IPNS exactly once.

**Why this pattern:**

- Eliminates per-file IPNS publish (biggest latency win)
- Maintains existing `addFileToFolder()` for single-file use
- Clean separation: upload service handles IPFS, folder service handles metadata

```typescript
// In folder.service.ts
export async function addFilesToFolder(params: {
  parentFolderState: FolderNode;
  files: Array<{
    cid: string;
    fileKeyEncrypted: string;
    fileIv: string;
    name: string;
    size: number;
  }>;
}): Promise<{ fileEntries: FileEntry[]; newSequenceNumber: bigint }> {
  // 1. Create all file entries (check name collisions)
  const fileEntries: FileEntry[] = [];
  const existingNames = new Set(params.parentFolderState.children.map((c) => c.name));

  for (const file of params.files) {
    if (existingNames.has(file.name)) {
      throw new Error(`A file with name "${file.name}" already exists`);
    }
    existingNames.add(file.name);

    const now = Date.now();
    fileEntries.push({
      type: 'file',
      id: crypto.randomUUID(),
      name: file.name,
      cid: file.cid,
      fileKeyEncrypted: file.fileKeyEncrypted,
      fileIv: file.fileIv,
      encryptionMode: 'GCM',
      size: file.size,
      createdAt: now,
      modifiedAt: now,
    });
  }

  // 2. Add ALL to children array
  const children = [...params.parentFolderState.children, ...fileEntries];

  // 3. Single updateFolderMetadata call (one IPNS publish)
  const { newSequenceNumber } = await updateFolderMetadata({
    folderId: params.parentFolderState.id,
    children,
    folderKey: params.parentFolderState.folderKey,
    ipnsPrivateKey: params.parentFolderState.ipnsPrivateKey,
    ipnsName: params.parentFolderState.ipnsName,
    sequenceNumber: params.parentFolderState.sequenceNumber,
  });

  return { fileEntries, newSequenceNumber };
}
```

### Pattern 3: Refactored Upload Orchestration (Frontend)

**What:** Upload flow becomes: encrypt all -> upload all -> register all in folder (single IPNS).

```text
Current flow (per file, sequential):
  for each file:
    encrypt -> upload -> addFileToFolder (includes IPNS publish)

New flow (batch):
  for each file:
    encrypt -> upload (new atomic endpoint with quota recording)
  then once:
    addFilesToFolder (single IPNS publish for all files)
```

### Recommended Project Structure Changes

```text
apps/api/src/ipfs/
  ipfs.controller.ts     # Add POST /ipfs/upload endpoint
  ipfs.module.ts         # Import VaultModule to access VaultService
  dto/
    upload.dto.ts        # NEW: UploadResponseDto
    index.ts             # Export new DTO

apps/web/src/
  services/
    upload.service.ts    # Use new /ipfs/upload endpoint
    folder.service.ts    # Add addFilesToFolder() batch function
  hooks/
    useFileUpload.ts     # Wire batch addFiles flow
    useFolder.ts         # Add addFiles() batch handler
  lib/api/
    ipfs.ts              # Update addToIpfs to use new endpoint
  stores/
    upload.store.ts      # Add 'registering' status for metadata phase
  components/file-browser/
    EmptyState.tsx        # Use batch addFiles
    UploadZone.tsx        # Use batch addFiles
```

### Anti-Patterns to Avoid

- **Do NOT move encryption to backend:** Zero-knowledge architecture means the server never sees plaintext or keys.
- **Do NOT move IPNS signing to backend:** The client holds the Ed25519 private keys. Backend only relays.
- **Do NOT wrap IPFS pin inside a DB transaction:** IPFS pin is an external service call that cannot be rolled back. If the DB transaction fails, you'd have a pinned blob with no record, which is acceptable (orphan cleanup can handle it).
- **Do NOT use client-side CID calculation for v1:** The todo notes this as a v2 enhancement. Matching CID calculation with Pinata's UnixFS chunking is non-trivial for files > 256KB.
- **Do NOT attempt to make IPNS publish atomic with DB:** IPNS is external and eventually consistent. The system already handles this via 30s polling sync.

## Don't Hand-Roll

| Problem             | Don't Build              | Use Instead                                             | Why                                             |
| ------------------- | ------------------------ | ------------------------------------------------------- | ----------------------------------------------- |
| File upload parsing | Custom multipart parser  | NestJS `FileInterceptor` + Multer                       | Already used, handles edge cases                |
| DB transactions     | Manual SQL transactions  | TypeORM `DataSource.transaction()` or `QueryRunner`     | Proper connection management, auto-rollback     |
| Quota enforcement   | Client-only tracking     | Server-side `VaultService.checkQuota()` + `recordPin()` | Client can be bypassed; server is authoritative |
| Retry logic         | Custom retry for IPNS    | Existing `withRetry()` in upload.service.ts             | Already implemented with exponential backoff    |
| Upload progress     | Custom progress tracking | Existing axios `onUploadProgress`                       | Already implemented                             |

## Common Pitfalls

### Pitfall 1: Breaking the Existing `/ipfs/add` Endpoint

**What goes wrong:** Removing or changing `/ipfs/add` breaks folder metadata uploads (which also use this endpoint to pin encrypted folder metadata JSON blobs).
**Why it happens:** Both file uploads and folder metadata updates use `/ipfs/add`. Only file uploads should use the new atomic endpoint.
**How to avoid:** Keep `/ipfs/add` as-is. Add the NEW endpoint as `/ipfs/upload`. The old endpoint serves folder metadata pins.
**Warning signs:** Folder operations (create, rename, delete) breaking after the refactor.

### Pitfall 2: Quota Double-Counting

**What goes wrong:** If the client still calls `quotaStore.addUsage()` AND the backend now records the pin, quota may be double-counted when the client refreshes quota from the server.
**How to avoid:** After upload, call `fetchQuota()` to resync client quota state from the server rather than locally incrementing. Or continue using local tracking for UI feedback but always treat server as authoritative.
**Warning signs:** Quota shown as used is much higher than actual usage.

### Pitfall 3: IPNS Publish Rate Limiting

**What goes wrong:** The IPNS publish endpoint has a rate limit of 10 publishes per minute per user. With batch upload this is fine (1 publish), but during development/testing with rapid retries it can hit the limit.
**How to avoid:** Batch IPNS publish (this phase's primary goal) naturally avoids this. For single-file uploads, the existing rate limit is sufficient.
**Warning signs:** 429 responses from `/ipns/publish`.

### Pitfall 4: Name Collision During Batch Upload

**What goes wrong:** Two files with the same name in a batch upload. The `addFilesToFolder` function would need to handle this.
**How to avoid:** Check for name collisions against existing children AND within the batch itself. Throw early with a clear error message identifying which files conflict.
**Warning signs:** Duplicate file entries in folder metadata.

### Pitfall 5: Stale Folder State During Upload

**What goes wrong:** Between starting and finishing a multi-file upload, another device might have synced and changed the folder's children. The batch `addFilesToFolder` would overwrite those changes.
**Why it happens:** Upload can take 30+ seconds for large batches, and sync polling is every 30 seconds.
**How to avoid:** This is an existing issue (last-write-wins per CONTEXT.md). For v1, accept this as a known limitation. The file data is never lost (CIDs are pinned), only folder metadata might temporarily miss entries until next sync.
**Warning signs:** Files disappearing after upload on multi-device setups.

### Pitfall 6: API Client Regeneration

**What goes wrong:** Adding a new endpoint to the API without regenerating the typed client means the frontend can't use it properly.
**How to avoid:** Always run `pnpm api:generate` after modifying API endpoints, DTOs, or controllers. Commit the regenerated files.
**Warning signs:** TypeScript errors in `apps/web/src/api/` after API changes.

### Pitfall 7: Multer Memory Usage for Large Files

**What goes wrong:** The 100MB file limit means Multer buffers 100MB in memory. The new endpoint adds quota check + DB write, keeping the buffer in memory slightly longer.
**How to avoid:** This is the same as the existing `/ipfs/add` endpoint behavior. No regression. If memory becomes an issue in the future, consider streaming to disk (Multer disk storage), but that's a future optimization.
**Warning signs:** OOM errors on constrained servers with concurrent large uploads.

## Code Examples

### Example 1: New Upload Response DTO

```typescript
// apps/api/src/ipfs/dto/upload.dto.ts
import { ApiProperty } from '@nestjs/swagger';

export class UploadResponseDto {
  @ApiProperty({
    description: 'The IPFS CID of the pinned file',
    example: 'bafkreigaknpexyvxt76zgkitavbwx6ejgfheup5oybpm77f3pxzrvwpfdi',
  })
  cid!: string;

  @ApiProperty({
    description: 'The size of the pinned file in bytes',
    example: 1024,
  })
  size!: number;

  @ApiProperty({
    description: 'Whether the pin was recorded for quota tracking',
    example: true,
  })
  recorded!: boolean;
}
```

### Example 2: IpfsModule Importing VaultModule

```typescript
// apps/api/src/ipfs/ipfs.module.ts - updated
import { VaultModule } from '../vault/vault.module';

@Module({})
export class IpfsModule {
  static forRootAsync(): DynamicModule {
    return {
      module: IpfsModule,
      imports: [ConfigModule, VaultModule], // Add VaultModule
      controllers: [IpfsController],
      providers: [
        /* existing providers */
      ],
      exports: [IPFS_PROVIDER],
    };
  }
}
```

### Example 3: TypeORM Transaction Pattern (If Needed)

```typescript
// TypeORM 0.3.x transaction via DataSource
import { DataSource } from 'typeorm';

constructor(
  @Inject(IPFS_PROVIDER) private readonly ipfsProvider: IpfsProvider,
  private readonly vaultService: VaultService,
  private readonly dataSource: DataSource,
) {}

// For operations that need true atomicity:
await this.dataSource.transaction(async (manager) => {
  // All DB operations in this callback share one transaction
  await manager.getRepository(PinnedCid).insert({ userId, cid, sizeBytes });
  // If any operation throws, entire transaction rolls back
});
```

**Note:** For the upload endpoint, a full transaction may not be necessary since `recordPin` uses `orIgnore()` (idempotent upsert). But the pattern is available if needed.

### Example 4: Updated Frontend Upload Flow

```typescript
// In UploadZone.tsx / EmptyState.tsx handleDrop
const uploadedFiles = await upload(acceptedFiles); // encrypt + upload to IPFS

// BATCH: register all files in folder with single IPNS publish
await addFiles(
  folderId,
  uploadedFiles.map((uploaded) => ({
    cid: uploaded.cid,
    wrappedKey: uploaded.wrappedKey,
    iv: uploaded.iv,
    originalName: uploaded.originalName,
    originalSize: uploaded.originalSize,
  }))
);
```

### Example 5: Updated addToIpfs to Use New Endpoint

```typescript
// apps/web/src/lib/api/ipfs.ts - updated
export async function addToIpfs(
  encryptedFile: Blob,
  onProgress?: (percent: number) => void,
  cancelToken?: CancelToken
): Promise<AddResponse> {
  const { accessToken } = useAuthStore.getState();
  const formData = new FormData();
  formData.append('file', encryptedFile);

  // Use new atomic endpoint that also records pin for quota
  const response = await axios.post<AddResponse>(`${BASE_URL}/ipfs/upload`, formData, {
    headers: { Authorization: `Bearer ${accessToken}` },
    onUploadProgress: (event: AxiosProgressEvent) => {
      if (event.total && onProgress) {
        onProgress(Math.round((event.loaded * 100) / event.total));
      }
    },
    cancelToken,
  });

  return response.data;
}
```

## State of the Art

| Old Approach               | Current Approach                                          | When Changed | Impact                                    |
| -------------------------- | --------------------------------------------------------- | ------------ | ----------------------------------------- |
| 3 requests per file upload | 1 request per file upload + 1 IPNS publish per batch      | This phase   | Latency reduction: ~60-80% for multi-file |
| Client-only quota tracking | Server-side quota enforcement (already exists, underused) | This phase   | Authoritative quota, prevents bypass      |
| Per-file IPNS publish      | Batch IPNS publish (once per upload batch)                | This phase   | Biggest latency win                       |

**Not changing (deferred):**

- Client-side CID calculation (v2 feature, per todo notes)
- Parallel file uploads (per CONTEXT.md: sequential uploads only)
- Retry token for IPNS failures (nice to have but IPNS is eventually consistent via sync)

## Detailed Change Impact Analysis

### Backend Changes (Low Risk)

1. **New `POST /ipfs/upload` endpoint** in `ipfs.controller.ts`:
   - Combines pin + quota check + record in one endpoint
   - Requires injecting `VaultService` (needs `VaultModule` import)
   - New `UploadResponseDto` DTO
   - All validation already exists (`MaxFileSizeValidator`, `ParseFilePipe`)

2. **`ipfs.module.ts`** needs to import `VaultModule` for `VaultService` access

3. **Existing `POST /ipfs/add`** remains unchanged (used by folder metadata updates)

4. **Run `pnpm api:generate`** to regenerate typed API client

### Frontend Changes (Medium Risk)

1. **`upload.service.ts`**: Update `addToIpfs` call or switch to new endpoint URL
2. **`folder.service.ts`**: Add `addFilesToFolder()` batch function
3. **`useFolder.ts`**: Add `addFiles()` batch handler alongside existing `addFile()`
4. **`EmptyState.tsx`** and **`UploadZone.tsx`**: Replace per-file `addFile` loop with batch `addFiles` call
5. **`upload.store.ts`**: Optionally add 'registering' status for metadata registration phase
6. **Quota management**: Switch from client-side `quotaStore.addUsage()` to server-authoritative `fetchQuota()` after upload

### Test Changes

1. **New unit tests** for `POST /ipfs/upload` endpoint (follow existing `ipfs.controller.spec.ts` pattern)
2. **Update existing frontend tests** if any reference the old upload flow
3. **E2E tests** should continue to pass (upload still works, just faster)

## Open Questions

1. **Should the old `/ipfs/add` endpoint record pins too?**
   - Currently it doesn't record pins. Only the new `/ipfs/upload` would.
   - Folder metadata pins are small (~1KB) and don't significantly affect quota.
   - Recommendation: Leave `/ipfs/add` as-is. Only file content pins matter for quota.

2. **Should upload cancellation abort mid-batch metadata registration?**
   - If 3 of 5 files uploaded successfully and user cancels, should we register the 3?
   - Recommendation: Yes, register whatever was successfully uploaded. Files are already pinned and consuming quota; making them visible is better than orphaning them.

3. **Race condition with sync on multi-device batch uploads:**
   - Two devices uploading simultaneously to the same folder could lose files.
   - This is an existing issue with last-write-wins.
   - Recommendation: Document as known limitation. CID data is never lost; only folder metadata reference may be temporarily missing.

## Sources

### Primary (HIGH confidence)

- **Codebase analysis:** Direct reading of all 13+ files listed in the "Files Involved" section
- **NestJS 11.x:** Using `FileInterceptor`, `ParseFilePipe`, `MaxFileSizeValidator` -- already in codebase, verified working
- **TypeORM 0.3.28:** Transaction support via `DataSource.transaction()` or `QueryRunner` -- documented in TypeORM docs

### Secondary (MEDIUM confidence)

- **Todo analysis:** `.planning/todos/pending/2026-01-22-atomic-file-upload-flow.md` -- detailed failure mode analysis with Option A recommendation
- **CodeRabbit review notes:** Confirmed per-file IPNS publish bottleneck and recommended batch approach

### Tertiary (LOW confidence)

- None -- all findings are from direct codebase analysis

## Metadata

**Confidence breakdown:**

- Standard stack: HIGH -- all libraries already in project, no new dependencies
- Architecture: HIGH -- patterns derived from direct codebase analysis and existing code patterns
- Pitfalls: HIGH -- identified from actual code flow tracing, not hypothetical
- Current flow understanding: HIGH -- every file in the chain was read and analyzed

**Research date:** 2026-02-07
**Valid until:** 2026-03-07 (stable -- this is internal refactoring, no external API changes)
